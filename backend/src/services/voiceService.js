/**
 * Service de synth√®se vocale OPTIMIS√â pour √©conomiser les cr√©dits ElevenLabs
 *
 * Strat√©gies d'√©conomie :
 * 1. CACHE AUDIO : Ne pas re-g√©n√©rer les phrases r√©p√©titives (~70% √©conomie)
 * 2. TEXTE CONCIS : R√©duire sans perdre le naturel (~30% √©conomie)
 * 3. PR√â-G√âN√âRATION : G√©n√©rer les phrases courantes √† l'avance (100% √©conomie)
 * 4. CHUNKS INTELLIGENTS : D√©couper et cacher les segments communs
 *
 * @module voiceService
 */

import fs from 'fs';
import path from 'path';
import crypto from 'crypto';

// ============================================
// CONFIGURATION
// ============================================

const ELEVENLABS_API_KEY = process.env.ELEVENLABS_API_KEY;
const ELEVENLABS_API_URL = 'https://api.elevenlabs.io/v1';

// Dossier de cache audio
const CACHE_DIR = path.join(process.cwd(), 'data', 'voice-cache');

// Cr√©er le dossier cache s'il n'existe pas
if (!fs.existsSync(CACHE_DIR)) {
  fs.mkdirSync(CACHE_DIR, { recursive: true });
  console.log('[VOICE SERVICE] Dossier cache cr√©√©:', CACHE_DIR);
}

// Statistiques d'utilisation
let stats = {
  totalCharacters: 0,
  cachedHits: 0,
  apiCalls: 0,
  charactersSaved: 0,
  sessionStart: new Date().toISOString()
};

// üìä Logger l'usage ElevenLabs pour tracking des co√ªts
async function logElevenLabsUsage(characters, voiceId, cached = false) {
  if (cached) return; // Ne pas logger les hits de cache (pas de co√ªt)

  try {
    const { supabase } = await import('../config/supabase.js');
    await supabase.from('twilio_call_logs').insert({
      channel: 'elevenlabs',
      direction: 'outbound',
      call_duration: characters, // On r√©utilise ce champ pour stocker les caract√®res
      from_number: voiceId,
      tenant_id: 'fatshairafro',
      sms_body: `TTS: ${characters} chars`,
    });
    console.log(`[VOICE] ‚úÖ Usage logg√©: ${characters} caract√®res`);
  } catch (err) {
    console.warn('[VOICE] ‚ö†Ô∏è Erreur logging usage:', err.message);
  }
}

// Voix par d√©faut (Ingrid - fran√ßaise naturelle)
const DEFAULT_VOICE_ID = process.env.ELEVENLABS_VOICE_ID || 'FFXYdAYPzn8Tw8KiHZqg';

// Param√®tres optimis√©s pour qualit√©/co√ªt
const VOICE_SETTINGS = {
  stability: 0.7,           // Plus stable pour le t√©l√©phone
  similarity_boost: 0.75,
  style: 0.35,              // Pas trop haut pour √©viter les artefacts
  use_speaker_boost: true
};

// Mod√®le : turbo = moins cher et plus rapide, v2 = meilleure qualit√©
const MODEL_ID = process.env.ELEVENLABS_MODEL || 'eleven_turbo_v2_5';

// ============================================
// PHRASES PR√â-G√âN√âR√âES (√† g√©n√©rer 1 fois)
// ============================================

const PREGENERATED_PHRASES = {
  // Salutations
  'bonjour': "Bonjour ! Comment allez-vous ?",
  'bonjour_matin': "Bonjour ! Bien dormi ?",
  'bonjour_aprem': "Bonjour ! Comment se passe votre journ√©e ?",
  'bonsoir': "Bonsoir ! Comment allez-vous ?",

  // Pr√©sentations
  'je_suis_halimah': "Moi c'est Halimah, enchant√©e !",
  'bienvenue': "Bienvenue chez Fat's Hair-Afro !",
  'bienvenue_complet': "Fat's Hair-Afro bonjour ! Moi c'est Halimah...",

  // Confirmations
  'ok': "D'accord !",
  'parfait': "Parfait !",
  'super': "Super !",
  'cest_note': "C'est not√© !",
  'tres_bien': "Tr√®s bien !",
  'entendu': "Bien entendu !",
  'cest_bon': "C'est bon !",
  'ca_marche': "√áa marche !",

  // Transitions
  'alors': "Alors...",
  'voyons': "Voyons voir...",
  'attendez': "Attendez, je v√©rifie...",
  'un_instant': "Un petit instant...",
  'je_regarde': "Je regarde √ßa...",
  'je_verifie': "Je v√©rifie les disponibilit√©s...",

  // Questions
  'ca_vous_va': "√áa vous va ?",
  'autre_chose': "Vous avez besoin d'autre chose ?",
  'des_questions': "Vous avez des questions ?",
  'on_fait_ca': "On fait comme √ßa ?",
  'vous_preferez_quand': "Vous pr√©f√©rez quand ?",
  'quel_jour': "Quel jour vous arrangerait ?",
  'quelle_heure': "√Ä quelle heure ?",
  'votre_adresse': "Quelle est votre adresse ?",
  'votre_nom': "C'est √† quel nom ?",
  'votre_telephone': "Votre num√©ro de t√©l√©phone ?",

  // Empathie
  'je_comprends': "Je comprends...",
  'pas_de_souci': "Pas de souci !",
  'aucun_probleme': "Aucun probl√®me !",
  'desolee': "Je suis d√©sol√©e...",
  'ah_mince': "Ah mince...",

  // Au revoir
  'au_revoir': "Au revoir, √† bient√¥t !",
  'a_samedi': "Allez, √† samedi !",
  'bonne_journee': "Bonne journ√©e !",
  'bonne_soiree': "Bonne soir√©e !",
  'prenez_soin': "Prenez soin de vous !",
  'a_tres_vite': "√Ä tr√®s vite !",
  'merci_au_revoir': "Merci et √† bient√¥t !",

  // Services courants
  'locks_reprise': "Reprise de locks, cinquante euros.",
  'locks_creation': "Cr√©ation de locks, deux cents euros.",
  'tresses_braids': "Des braids, soixante euros.",
  'soin_complet': "Un soin complet, cinquante euros.",

  // Lieux
  'chez_vous_ou_fatou': "Chez vous ou chez Fatou ?",
  'domicile_ou_salon': "√Ä domicile ou au salon ?",
  'adresse_fatou': "C'est au huit rue des Monts Rouges, √† Franconville."
};

// ============================================
// CACHE AUDIO
// ============================================

/**
 * G√©n√®re un hash unique pour un texte
 * @param {string} text - Texte √† hasher
 * @param {string} voiceId - ID de la voix
 * @returns {string} - Hash MD5
 */
function getTextHash(text, voiceId) {
  const normalized = text.toLowerCase().trim().replace(/\s+/g, ' ');
  return crypto.createHash('md5').update(`${normalized}_${voiceId}`).digest('hex');
}

/**
 * V√©rifie si l'audio est en cache
 * @param {string} text - Texte √† v√©rifier
 * @param {string} voiceId - ID de la voix
 * @returns {Buffer|null} - Buffer audio ou null
 */
function getCachedAudio(text, voiceId = DEFAULT_VOICE_ID) {
  const hash = getTextHash(text, voiceId);
  const cachePath = path.join(CACHE_DIR, `${hash}.mp3`);

  if (fs.existsSync(cachePath)) {
    stats.cachedHits++;
    stats.charactersSaved += text.length;
    console.log(`[VOICE] Cache HIT: "${text.substring(0, 30)}..." (${text.length} chars √©conomis√©s)`);
    return fs.readFileSync(cachePath);
  }

  return null;
}

/**
 * Sauvegarde l'audio en cache
 * @param {string} text - Texte g√©n√©r√©
 * @param {string} voiceId - ID de la voix
 * @param {Buffer} audioBuffer - Buffer audio √† cacher
 */
function cacheAudio(text, voiceId, audioBuffer) {
  const hash = getTextHash(text, voiceId);
  const cachePath = path.join(CACHE_DIR, `${hash}.mp3`);
  fs.writeFileSync(cachePath, audioBuffer);
  console.log(`[VOICE] Cached: "${text.substring(0, 30)}..."`);
}

// ============================================
// OPTIMISATION DU TEXTE
// ============================================

/**
 * Optimise le texte pour r√©duire les caract√®res sans perdre le naturel
 * @param {string} text - Texte √† optimiser
 * @returns {string} - Texte optimis√©
 */
function optimizeText(text) {
  let optimized = text;

  // 1. Supprimer les espaces multiples
  optimized = optimized.replace(/\s+/g, ' ').trim();

  // 2. Supprimer les emojis (ne se prononcent pas)
  optimized = optimized.replace(/[\u{1F300}-\u{1F9FF}]|[\u{2600}-\u{26FF}]|[\u{2700}-\u{27BF}]/gu, '');

  // 3. Raccourcir les formulations verbeuses
  const shortenings = {
    "je vous confirme que": "c'est confirm√©,",
    "je vous informe que": "",
    "je souhaiterais": "je voudrais",
    "est-ce que vous": "vous",
    "est-ce que": "",
    "n'h√©sitez pas √†": "",
    "je me permets de": "",
    "je vous remercie pour": "merci pour",
    "je vous remercie de": "merci de",
    "dans le cadre de": "pour",
    "au niveau de": "pour",
    "en ce qui concerne": "pour",
    "il est possible de": "on peut",
    "afin de": "pour",
    "permettre de": "",
    "actuellement": "",
    "√©galement": "aussi",
    "n√©anmoins": "mais",
    "toutefois": "mais",
    "cependant": "mais",
    "par cons√©quent": "donc",
    "je reste √† votre disposition": "",
    "n'h√©sitez pas": "",
    "il est important de noter que": "",
    "je tiens √† vous informer que": "",
    "je vous prie de": ""
  };

  for (const [long, short] of Object.entries(shortenings)) {
    optimized = optimized.replace(new RegExp(long, 'gi'), short);
  }

  // 4. Convertir les symboles
  optimized = optimized.replace(/(\d+)\s*‚Ç¨/g, '$1 euro');
  optimized = optimized.replace(/(\d+)\s*EUR/gi, '$1 euro');
  // D'abord les heures rondes (9h00, 17H00 ‚Üí "9 heures", "17 heures")
  optimized = optimized.replace(/(\d{1,2})\s*[hH]00(?!\s*heure)/g, '$1 heures');
  // Puis les heures avec minutes (9h30 ‚Üí "9 heures 30")
  optimized = optimized.replace(/(\d{1,2})\s*[hH](\d{2})(?!\s*heure)/g, '$1 heures $2');
  // Puis les heures sans minutes (9h ‚Üí "9 heures") ‚Äî (?![a-z√†-√º\d]) √©vite de matcher le h de "heures"
  optimized = optimized.replace(/(\d{1,2})\s*[hH](?![a-z\u00e0-\u00fc\d])/gi, '$1 heures');

  // 5. Nettoyer les espaces cr√©√©s
  optimized = optimized.replace(/\s+/g, ' ').trim();
  optimized = optimized.replace(/\s+([,.\?!])/g, '$1');
  optimized = optimized.replace(/,\s*,/g, ',');

  // 6. Supprimer le markdown
  optimized = optimized.replace(/\*\*(.*?)\*\*/g, '$1');
  optimized = optimized.replace(/\*(.*?)\*/g, '$1');
  optimized = optimized.replace(/`(.*?)`/g, '$1');
  optimized = optimized.replace(/#{1,6}\s/g, '');
  optimized = optimized.replace(/[-*+]\s/g, '');

  return optimized;
}

/**
 * D√©tecte si une phrase pr√©-g√©n√©r√©e peut √™tre utilis√©e
 * @param {string} text - Texte √† analyser
 * @returns {string|null} - Cl√© de la phrase pr√©-g√©n√©r√©e ou null
 */
function findPregeneratedMatch(text) {
  const normalized = text.toLowerCase().trim();

  // Correspondance exacte
  for (const [key, phrase] of Object.entries(PREGENERATED_PHRASES)) {
    if (normalized === phrase.toLowerCase()) {
      return key;
    }
  }

  // D√©tection par patterns
  if (/^bonjour\s*[!.]?\s*$/i.test(normalized)) return 'bonjour';
  if (/^bonsoir\s*[!.]?\s*$/i.test(normalized)) return 'bonsoir';
  if (/^d'accord\s*[!.]?\s*$/i.test(normalized) || /^ok\s*[!.]?\s*$/i.test(normalized)) return 'ok';
  if (/^parfait\s*[!.]?\s*$/i.test(normalized)) return 'parfait';
  if (/^super\s*[!.]?\s*$/i.test(normalized)) return 'super';
  if (/^c'est not[e√©]\s*[!.]?\s*$/i.test(normalized)) return 'cest_note';
  if (/^tr[e√®]s bien\s*[!.]?\s*$/i.test(normalized)) return 'tres_bien';
  if (/au revoir|[a√†] bient[o√¥]t/i.test(normalized)) return 'au_revoir';
  if (/[√ßc]a vous va\s*\??\s*$/i.test(normalized)) return 'ca_vous_va';
  if (/je comprends/i.test(normalized)) return 'je_comprends';
  if (/pas de souci/i.test(normalized)) return 'pas_de_souci';
  if (/un instant|un moment/i.test(normalized)) return 'un_instant';
  if (/je v[e√©]rifie/i.test(normalized)) return 'je_verifie';
  if (/bonne journ[e√©]e/i.test(normalized)) return 'bonne_journee';
  if (/bonne soir[e√©]e/i.test(normalized)) return 'bonne_soiree';

  return null;
}

// ============================================
// APPEL API ELEVENLABS
// ============================================

/**
 * Appelle l'API ElevenLabs (seulement si pas en cache)
 * @param {string} text - Texte √† synth√©tiser
 * @param {string} voiceId - ID de la voix
 * @returns {Promise<Buffer>} - Buffer audio
 */
async function callElevenLabsAPI(text, voiceId = DEFAULT_VOICE_ID) {
  if (!ELEVENLABS_API_KEY) {
    throw new Error('ELEVENLABS_API_KEY non configur√©e');
  }

  stats.apiCalls++;
  stats.totalCharacters += text.length;

  console.log(`[VOICE] API Call: "${text.substring(0, 40)}..." (${text.length} chars)`);

  const response = await fetch(`${ELEVENLABS_API_URL}/text-to-speech/${voiceId}`, {
    method: 'POST',
    headers: {
      'Accept': 'audio/mpeg',
      'Content-Type': 'application/json',
      'xi-api-key': ELEVENLABS_API_KEY
    },
    body: JSON.stringify({
      text: text,
      model_id: MODEL_ID,
      voice_settings: VOICE_SETTINGS,
      speed: 0.9
    })
  });

  if (!response.ok) {
    const error = await response.text();
    throw new Error(`ElevenLabs error ${response.status}: ${error}`);
  }

  const audioBuffer = Buffer.from(await response.arrayBuffer());

  // üìä Logger l'usage pour tracking des co√ªts
  await logElevenLabsUsage(text.length, voiceId);

  return audioBuffer;
}

// ============================================
// FONCTIONS PRINCIPALES
// ============================================

/**
 * Convertit du texte en audio avec optimisation maximale
 * @param {string} text - Texte √† convertir
 * @param {Object} options - Options
 * @returns {Promise<Object>} - R√©sultat avec audio et stats
 */
async function textToSpeech(text, options = {}) {
  const {
    voiceId = DEFAULT_VOICE_ID,
    useCache = true,
    optimize = true
  } = options;

  // 1. Optimiser le texte si demand√©
  let processedText = optimize ? optimizeText(text) : text;

  // Log l'√©conomie
  if (optimize && processedText.length < text.length) {
    const saved = text.length - processedText.length;
    console.log(`[VOICE] Optimis√©: ${text.length} ‚Üí ${processedText.length} chars (-${saved})`);
  }

  // 2. V√©rifier le cache
  if (useCache) {
    const cached = getCachedAudio(processedText, voiceId);
    if (cached) {
      return {
        success: true,
        audio: cached,
        fromCache: true,
        characters: 0  // Pas de caract√®res consomm√©s
      };
    }
  }

  // 3. Appeler l'API
  try {
    const audio = await callElevenLabsAPI(processedText, voiceId);

    // 4. Mettre en cache
    if (useCache) {
      cacheAudio(processedText, voiceId, audio);
    }

    return {
      success: true,
      audio,
      fromCache: false,
      characters: processedText.length
    };

  } catch (error) {
    console.error('[VOICE] Erreur TTS:', error);
    return { success: false, error: error.message };
  }
}

/**
 * G√©n√®re l'audio pour une r√©ponse compl√®te (d√©coupe en segments)
 * @param {string} text - Texte complet
 * @param {Object} options - Options
 * @returns {Promise<Object>} - R√©sultat avec audio et stats
 */
async function textToSpeechSmart(text, options = {}) {
  const { voiceId = DEFAULT_VOICE_ID } = options;

  // D√©couper en segments (par phrase)
  const segments = text
    .split(/(?<=[.!?])\s+/)
    .filter(s => s.trim().length > 0);

  const audioBuffers = [];
  let totalChars = 0;
  let cachedChars = 0;

  for (const segment of segments) {
    // V√©rifier si c'est une phrase pr√©-g√©n√©r√©e
    const pregenKey = findPregeneratedMatch(segment);
    const textToGenerate = pregenKey
      ? PREGENERATED_PHRASES[pregenKey]
      : segment;

    const result = await textToSpeech(textToGenerate, { voiceId });

    if (result.success) {
      audioBuffers.push(result.audio);
      if (result.fromCache) {
        cachedChars += textToGenerate.length;
      } else {
        totalChars += result.characters;
      }
    }
  }

  // Concat√©ner les audios
  const finalAudio = Buffer.concat(audioBuffers);

  return {
    success: true,
    audio: finalAudio,
    stats: {
      segments: segments.length,
      charactersUsed: totalChars,
      charactersCached: cachedChars,
      percentSaved: cachedChars > 0
        ? Math.round((cachedChars / (totalChars + cachedChars)) * 100)
        : 0
    }
  };
}

/**
 * Synth√®se vocale en streaming pour r√©ponses temps r√©el
 * @param {string} text - Texte √† convertir
 * @param {Object} options - Options
 * @returns {Promise<ReadableStream>} - Stream audio
 */
async function textToSpeechStream(text, options = {}) {
  if (!ELEVENLABS_API_KEY) {
    console.warn('[VOICE] ElevenLabs API key non configur√©e');
    return null;
  }

  const processedText = optimizeText(text);
  const voiceId = options.voiceId || DEFAULT_VOICE_ID;

  console.log(`[VOICE] Stream: "${processedText.substring(0, 50)}..."`);

  try {
    const response = await fetch(`${ELEVENLABS_API_URL}/text-to-speech/${voiceId}/stream`, {
      method: 'POST',
      headers: {
        'Accept': 'audio/mpeg',
        'Content-Type': 'application/json',
        'xi-api-key': ELEVENLABS_API_KEY
      },
      body: JSON.stringify({
        text: processedText,
        model_id: MODEL_ID,
        voice_settings: VOICE_SETTINGS,
        speed: 0.9,
        optimize_streaming_latency: 3
      })
    });

    if (!response.ok) {
      const errorText = await response.text();
      throw new Error(`ElevenLabs streaming error ${response.status}: ${errorText}`);
    }

    stats.apiCalls++;
    stats.totalCharacters += processedText.length;

    // üìä Logger l'usage pour tracking des co√ªts
    await logElevenLabsUsage(processedText.length, voiceId);

    return response.body;

  } catch (error) {
    console.error('[VOICE] Erreur stream:', error.message);
    throw error;
  }
}

// ============================================
// PR√â-G√âN√âRATION DES PHRASES COURANTES
// ============================================

/**
 * Pr√©-g√©n√®re toutes les phrases courantes (√† appeler au d√©marrage ou 1 fois)
 * @param {string} voiceId - ID de la voix
 * @returns {Promise<Object>} - R√©sultat avec compteurs
 */
async function pregenerateCommonPhrases(voiceId = DEFAULT_VOICE_ID) {
  console.log('[VOICE] Pr√©-g√©n√©ration des phrases courantes...');

  let generated = 0;
  let skipped = 0;
  let errors = 0;

  const phrases = Object.entries(PREGENERATED_PHRASES);

  for (const [key, phrase] of phrases) {
    // V√©rifier si d√©j√† en cache
    const cached = getCachedAudio(phrase, voiceId);
    if (cached) {
      skipped++;
      continue;
    }

    // G√©n√©rer et cacher
    try {
      const result = await textToSpeech(phrase, { voiceId, useCache: true, optimize: false });
      if (result.success) {
        generated++;
        console.log(`[VOICE] G√©n√©r√©: ${key}`);
      } else {
        errors++;
      }
    } catch (error) {
      console.error(`[VOICE] Erreur pour ${key}:`, error.message);
      errors++;
    }

    // Pause pour √©viter le rate limiting
    await new Promise(r => setTimeout(r, 500));
  }

  console.log(`[VOICE] Pr√©-g√©n√©ration termin√©e: ${generated} g√©n√©r√©s, ${skipped} en cache, ${errors} erreurs`);

  return { generated, skipped, errors, total: phrases.length };
}

// ============================================
// GESTION DU CACHE
// ============================================

/**
 * Vide le cache audio
 * @returns {Object} - Nombre de fichiers supprim√©s
 */
function clearCache() {
  const files = fs.readdirSync(CACHE_DIR);
  files.forEach(file => {
    if (file.endsWith('.mp3')) {
      fs.unlinkSync(path.join(CACHE_DIR, file));
    }
  });
  console.log(`[VOICE] Cache vid√©: ${files.length} fichiers supprim√©s`);
  return { cleared: files.length };
}

/**
 * Statistiques du cache
 * @returns {Object} - Stats du cache et de la session
 */
function getCacheStats() {
  let files = [];
  let totalSize = 0;

  try {
    files = fs.readdirSync(CACHE_DIR).filter(f => f.endsWith('.mp3'));
    files.forEach(file => {
      const stat = fs.statSync(path.join(CACHE_DIR, file));
      totalSize += stat.size;
    });
  } catch (error) {
    console.error('[VOICE] Erreur lecture cache:', error.message);
  }

  return {
    cacheFiles: files.length,
    cacheSize: `${(totalSize / 1024 / 1024).toFixed(2)} MB`,
    ...stats,
    savingsPercent: stats.totalCharacters > 0
      ? Math.round((stats.charactersSaved / (stats.totalCharacters + stats.charactersSaved)) * 100)
      : 0
  };
}

// ============================================
// UTILITAIRES
// ============================================

/**
 * Obtenir le quota ElevenLabs restant
 * @returns {Promise<Object>} - Informations de quota
 */
async function getQuota() {
  if (!ELEVENLABS_API_KEY) {
    return { available: false, reason: 'API key non configur√©e' };
  }

  try {
    const response = await fetch(`${ELEVENLABS_API_URL}/user/subscription`, {
      headers: { 'xi-api-key': ELEVENLABS_API_KEY }
    });

    if (!response.ok) {
      throw new Error(`Quota check failed: ${response.status}`);
    }

    const data = await response.json();
    return {
      available: true,
      used: data.character_count,
      limit: data.character_limit,
      remaining: data.character_limit - data.character_count,
      percentUsed: Math.round((data.character_count / data.character_limit) * 100),
      tier: data.tier
    };
  } catch (error) {
    console.error('[VOICE] Erreur quota:', error.message);
    return { available: false, error: error.message };
  }
}

/**
 * Liste les voix disponibles
 * @returns {Promise<Array>} - Liste des voix
 */
async function listVoices() {
  if (!ELEVENLABS_API_KEY) {
    return [];
  }

  try {
    const response = await fetch(`${ELEVENLABS_API_URL}/voices`, {
      headers: { 'xi-api-key': ELEVENLABS_API_KEY }
    });

    if (!response.ok) {
      throw new Error(`Voice list failed: ${response.status}`);
    }

    const data = await response.json();
    return data.voices.map(v => ({
      id: v.voice_id,
      name: v.name,
      category: v.category,
      labels: v.labels
    }));
  } catch (error) {
    console.error('[VOICE] Erreur liste voix:', error.message);
    return [];
  }
}

/**
 * R√©initialise les statistiques de session
 * @returns {Object} - Stats r√©initialis√©es
 */
function resetStats() {
  stats = {
    totalCharacters: 0,
    cachedHits: 0,
    apiCalls: 0,
    charactersSaved: 0,
    sessionStart: new Date().toISOString()
  };
  return stats;
}

/**
 * V√©rifie si le service est configur√©
 * @returns {boolean}
 */
function isConfigured() {
  return !!ELEVENLABS_API_KEY;
}

// ============================================
// EXPORTS
// ============================================

export default {
  textToSpeech,
  textToSpeechSmart,
  textToSpeechStream,
  pregenerateCommonPhrases,
  clearCache,
  getCacheStats,
  getQuota,
  listVoices,
  resetStats,
  isConfigured,
  optimizeText,
  findPregeneratedMatch,
  getTextHash,
  PREGENERATED_PHRASES,
  VOICE_SETTINGS,
  DEFAULT_VOICE_ID,
  CACHE_DIR
};

export {
  textToSpeech,
  textToSpeechSmart,
  textToSpeechStream,
  pregenerateCommonPhrases,
  clearCache,
  getCacheStats,
  getQuota,
  listVoices,
  resetStats,
  isConfigured,
  optimizeText,
  findPregeneratedMatch,
  getTextHash,
  PREGENERATED_PHRASES,
  VOICE_SETTINGS,
  DEFAULT_VOICE_ID,
  CACHE_DIR
};
